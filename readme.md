# Documenta√ß√£o do Projeto ‚Äì Pipeline de Dados NYC 311

**Respons√°vel:** Izabela Pereira Giacomeli  
**Data da √∫ltima atualiza√ß√£o:** 31 de dezembro de 2025  

---

## üîó Links √öteis
* **Dashboard:** [Visualizar Looker Studio](https://lookerstudio.google.com/reporting/ab473f47-2316-4d03-8e4e-d00f05a14a02)

---

## üìù Vis√£o Geral
Este projeto foi desenvolvido com o objetivo de construir um pipeline de dados completo para an√°lise das reclama√ß√µes do servi√ßo da prefeitura de Nova York, **NYC 311**.

A arquitetura utiliza:
* **Python:** Ingest√£o de dados via API.
* **Google Cloud Storage (GCS):** Camada de armazenamento (Data Lake).
* **BigQuery:** Processamento, modelagem e Data Warehousing.
* **Looker Studio:** Consumo final e visualiza√ß√£o.

![Arquitetura do Pipeline]("Imagens\Diagrama\arquitetura_pipeline.png.png")  
*Figura 1. Arquitetura do pipeline de dados desenvolvido.*

---

## üìÇ Fonte de Dados
A fonte de dados deste projeto √© o **NYC Open Data ‚Äì 311 Service Requests**, um portal oficial da cidade de Nova York que disponibiliza informa√ß√µes p√∫blicas sobre solicita√ß√µes e reclama√ß√µes registradas pelo servi√ßo 311 desde 2010 at√© o presente.
O conjunto de dados √© disponibilizado por meio de uma API RESTful, permitindo acesso program√°tico aos registros em formato estruturado. Cada registro representa uma solicita√ß√£o de servi√ßo ou reclama√ß√£o feita pela popula√ß√£o e cont√©m informa√ß√µes como data de abertura e fechamento, tipo de reclama√ß√£o, ag√™ncia respons√°vel, status, localiza√ß√£o e outros atributos relevantes.
Essa fonte foi escolhida por ser oficial, p√∫blica, confi√°vel e amplamente utilizada em an√°lises urbanas, al√©m de possuir grande volume de dados, o que a torna ideal para demonstrar um pipeline de dados completo, escal√°vel e orientado √† an√°lise.


---

## ‚öôÔ∏è Ingest√£o dos Dados

A ingest√£o dos dados foi realizada via API p√∫blica do NYC 311, pois o download direto do arquivo CSV completo pelo site n√£o era vi√°vel. O arquivo √© muito grande, o carregamento frequentemente n√£o conclu√≠a e, quando conclu√≠a, o CSV vinha corrompido, inviabilizando o uso.
Para resolver esse problema, foi desenvolvido um c√≥digo em Python que faz a extra√ß√£o dos dados de forma controlada e incremental. A estrat√©gia adotada foi dividir a ingest√£o por intervalos mensais e utilizar pagina√ß√£o (`limit` e `offset`) para evitar sobrecarga e perda de dados.
De forma resumida, o c√≥digo:
- Consome a API do NYC 311;
- Filtra os dados pela data de cria√ß√£o da reclama√ß√£o;
- Divide o per√≠odo informado em meses;
- Faz m√∫ltiplas requisi√ß√µes paginadas de at√© 50 mil registros;
- Gera arquivos CSV por m√™s e por offset;
- Envia automaticamente esses arquivos para um bucket no Google Cloud Storage;
- Verifica se o arquivo j√° existe no bucket antes de baixar novamente, evitando reprocessamento.
Os arquivos s√£o organizados no GCS seguindo um padr√£o de nomenclatura que facilita o controle e a leitura posterior no BigQuery, ficando armazenados na pasta `landing_nyc_311`. Essa abordagem garantiu estabilidade no processo de ingest√£o, al√©m de permitir reprocessamentos parciais caso necess√°rio.


---

## üèóÔ∏è Arquitetura de Medalh√£o (Camadas no BigQuery)

### 1. Camada Landing
A camada Landing foi criada no BigQuery utilizando uma tabela externa, apontando diretamente para os arquivos CSV armazenados no Google Cloud Storage.
Nesta etapa, os dados permanecem em seu formato original, sem transforma√ß√µes relevantes, servindo apenas como ponto de leitura inicial. As colunas ainda est√£o em ingl√™s e todos os campos s√£o tratados como texto.
Ap√≥s a cria√ß√£o da tabela externa, foi realizada uma valida√ß√£o b√°sica da ingest√£o, verificando:
- A data m√≠nima e m√°xima de cria√ß√£o das reclama√ß√µes;
- O total de registros carregados.
Essa valida√ß√£o garante que o per√≠odo esperado foi corretamente ingerido.


### 2. Camada Raw
A camada Raw tem como foco preparar os dados para tratamento, realizando ajustes estruturais sem alterar o conte√∫do original das informa√ß√µes.
Nessa etapa foram feitas principalmente:
- Convers√µes de tipo (datas para TIMESTAMP, chaves e coordenadas para tipos num√©ricos);
- Tradu√ß√£o e padroniza√ß√£o dos nomes das colunas do ingl√™s para o portugu√™s;
- Organiza√ß√£o do schema de forma mais leg√≠vel e consistente.
Essa camada preserva a fidelidade dos dados de origem, funcionando como uma vers√£o ‚Äúbruta tratada‚Äù, pronta para receber regras de qualidade.


### 3. Camada Staging
Onde ocorre o "cora√ß√£o" do tratamento:
* **Limpeza:** Substitui√ß√£o de nulos por "N√£o informado".
* **Padroniza√ß√£o:** Formata√ß√£o de CEPs e textos.
* **Regras de Neg√≥cio:** Cria√ß√£o de colunas como `tempo_resolucao_dias` e `categoria_tempo_resolucao`.

A camada Staging √© onde acontece a maior parte do tratamento dos dados e a aplica√ß√£o das regras de neg√≥cio, funcionando como um contrato de dados est√°vel entre a engenharia e o consumo anal√≠tico.
Nessa etapa, os dados passam por um processo aprofundado de padroniza√ß√£o, valida√ß√£o e limpeza, com foco em garantir qualidade, consist√™ncia e confiabilidade para as an√°lises. Entre os principais tratamentos realizados est√£o:
- Padroniza√ß√£o de textos (formata√ß√£o, capitaliza√ß√£o e consist√™ncia);
- Substitui√ß√£o de valores nulos ou inv√°lidos por ‚ÄúN√£o informado‚Äù quando aplic√°vel;
- Normaliza√ß√£o de c√≥digos como N/A, UNKNOWN e Unspecified, tamb√©m convertidos para ‚ÄúN√£o informado‚Äù;
- Valida√ß√£o e padroniza√ß√£o de CEPs, garantindo o formato de at√© 5 d√≠gitos num√©ricos;
- Remo√ß√£o de textos suspeitos ou inconsistentes na coluna tipo_reclamacao;
- Valida√ß√£o de datas inconsistentes, garantindo que o tempo de resolu√ß√£o seja calculado apenas quando a data de fechamento √© v√°lida e posterior √† data de cria√ß√£o.
Al√©m disso, nesta camada foram criados campos e m√©tricas derivadas fundamentais para a an√°lise, como:
- `status_analise`, que agrupa os diversos status t√©cnicos em categorias mais simples e compreens√≠veis;
- `tempo_resolucao_dias`, calculando o n√∫mero de dias entre abertura e fechamento da reclama√ß√£o;
- `categoria_tempo_resolucao`, que classifica o tempo de resolu√ß√£o das reclama√ß√µes em r√°pida, m√©dia ou lenta.
A camada Staging √© fundamental para centralizar regras de neg√≥cio, evitar retrabalho nas camadas anal√≠ticas e garantir que as tabelas da camada Trusted sejam constru√≠das a partir de dados j√° validados e padronizados.


### 4. Camada Trusted
A camada Trusted concentra tabelas j√° consolidadas e prontas para consumo anal√≠tico.
A partir da Staging, foram criadas diversas tabelas espec√≠ficas para responder perguntas de neg√≥cio, como:
- Quais s√£o os tipos de reclama√ß√£o mais frequentes;
- Quais bairros concentram mais reclama√ß√µes;
- Qual o status atual das reclama√ß√µes;
- Quanto tempo, em m√©dia, cada reclama√ß√£o leva para ser resolvida;
- Como as ag√™ncias se comportam em volume e efici√™ncia;
- Quais ag√™ncias concentram mais casos classificados como lentos;
- Quais s√£o os principais canais de abertura das reclama√ß√µes;
- Como o volume de reclama√ß√µes evolui ao longo do tempo.
Tamb√©m foi criada uma tabela geral (`trusted_nyc_geral`), que re√∫ne as principais dimens√µes e fatos do conjunto de dados. Essa tabela funciona como a principal fonte de dados para o Looker Studio, simplificando a constru√ß√£o do dashboard e garantindo uma √∫nica fonte de verdade.
A tabela trusted_nyc_geral possui a seguinte estrutura:

#### Estrutura da Tabela `trusted_nyc_geral`
### Estrutura da Tabela `trusted_nyc_geral`

| Coluna | Tipo | Descri√ß√£o |
|------|------|-----------|
| `chave_unica` | INTEGER | Identificador √∫nico da reclama√ß√£o no sistema NYC 311 |
| `agencia` | STRING | C√≥digo da ag√™ncia respons√°vel pelo atendimento da reclama√ß√£o |
| `nome_agencia` | STRING | Nome completo da ag√™ncia respons√°vel pela reclama√ß√£o |
| `bairro` | STRING | Bairro onde a reclama√ß√£o foi registrada |
| `tipo_reclamacao` | STRING | Tipo ou categoria da reclama√ß√£o informada pelo cidad√£o |
| `status_reclamacao` | STRING | Status atual da reclama√ß√£o (Resolvido, Em andamento, Cancelado ou N√£o especificado) |
| `data_criacao` | TIMESTAMP | Data e hora de abertura da reclama√ß√£o |
| `data_fechamento` | TIMESTAMP | Data e hora de fechamento da reclama√ß√£o, quando aplic√°vel |
| `ano` | INTEGER | Ano de cria√ß√£o da reclama√ß√£o, derivado da data de abertura |
| `dias_para_resolver` | INTEGER | Quantidade de dias entre a data de cria√ß√£o e a data de fechamento |
| `categoria_tempo_resolucao` | STRING | Classifica√ß√£o do tempo de resolu√ß√£o (R√°pida, M√©dia ou Lenta) |
| `tipo_canal_abertura` | STRING | Canal utilizado para abertura da reclama√ß√£o (Mobile, Online, Phone ou N√£o informado) |
*Tabela 1. Estrutura da tabela trusted_nyc_geral*

---

## üìä Visualiza√ß√£o dos Dados
Os dados da camada Trusted s√£o consumidos no Looker Studio, onde foram constru√≠do o dashboard para an√°lise de volume de reclama√ß√µes, desempenho das ag√™ncias, tempo de resolu√ß√£o e distribui√ß√£o das reclama√ß√µes ao longo do tempo e por regi√£o.

---

## üöÄ Considera√ß√µes Finais 
Este projeto demonstra a constru√ß√£o de um pipeline de dados completo, desde a ingest√£o at√© a visualiza√ß√£o, aplicando boas pr√°ticas de Engenharia de Dados e modelagem anal√≠tica. A arquitetura adotada √© escal√°vel, organizada e preparada para an√°lises consistentes, podendo ser facilmente expandida para novos per√≠odos ou para a inclus√£o de novas m√©tricas.
Como evolu√ß√£o do projeto, o script de ingest√£o em Python poderia ser executado por meio de uma ferramenta de orquestra√ß√£o, como o Apache Airflow, reduzindo a depend√™ncia de execu√ß√µes manuais e de ambientes locais, al√©m de aumentar a confiabilidade e a rastreabilidade do processo.
Da mesma forma, a utiliza√ß√£o de ferramentas como o dbt permitiria uma organiza√ß√£o ainda mais robusta do modelo de dados, com versionamento, documenta√ß√£o das colunas, aplica√ß√£o de testes de consist√™ncia e valida√ß√µes de qualidade, fortalecendo a governan√ßa e a manuten√ß√£o do pipeline ao longo do tempo.

